{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b862f3-3d84-4e4b-bd0c-137d90ebabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.voc_superpixels import VOCSuperpixels\n",
    "from dataset.coco_superpixels import COCOSuperpixels\n",
    "\n",
    "import torch_geometric\n",
    "import torch\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566c2e4-a213-4223-a336-04a71b41ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_dataset_splits(datasets):\n",
    "    \"\"\"Join train, val, test datasets into one dataset object.\n",
    "\n",
    "    Args:\n",
    "        datasets: list of 3 PyG datasets to merge\n",
    "\n",
    "    Returns:\n",
    "        joint dataset with `split_idxs` property storing the split indices\n",
    "    \"\"\"\n",
    "    assert len(datasets) == 3, \"Expecting train, val, test datasets\"\n",
    "\n",
    "    n1, n2, n3 = len(datasets[0]), len(datasets[1]), len(datasets[2])\n",
    "    data_list = [datasets[0].get(i) for i in range(n1)] + \\\n",
    "                [datasets[1].get(i) for i in range(n2)] + \\\n",
    "                [datasets[2].get(i) for i in range(n3)]\n",
    "\n",
    "    datasets[0]._indices = None\n",
    "    datasets[0]._data_list = data_list\n",
    "    datasets[0].data, datasets[0].slices = datasets[0].collate(data_list)\n",
    "    split_idxs = [list(range(n1)),\n",
    "                  list(range(n1, n1 + n2)),\n",
    "                  list(range(n1 + n2, n1 + n2 + n3))]\n",
    "    datasets[0].split_idxs = split_idxs\n",
    "\n",
    "    return datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf1510-cf68-46d3-9038-620c97ac59d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbcf153-c348-4b3e-bbcd-944e70d0b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(voc_dataset):\n",
    "    total_nodes, total_edges, avg_nodes, avg_edges = 0,0,0,0\n",
    "    all_node_degs = torch.empty(0)\n",
    "    all_avg_shortest_paths, all_diameters = [], []\n",
    "    for g in tqdm(voc_dataset):\n",
    "        total_nodes += g.num_nodes\n",
    "        total_edges += g.num_edges\n",
    "        idx = g.edge_index[1]\n",
    "        deg = torch_geometric.utils.degree(idx, g.num_nodes, dtype=torch.long)\n",
    "        all_node_degs = torch.cat((all_node_degs, deg))\n",
    "        g_nx = torch_geometric.utils.to_networkx(g)\n",
    "        \n",
    "        \n",
    "        # !!! NOTE\n",
    "        # For shortest path and diameter computations, we convert the digraph to undirected\n",
    "        g_nx = g_nx.to_undirected()\n",
    "        all_avg_shortest_paths.append(nx.average_shortest_path_length(g_nx))\n",
    "        all_diameters.append(nx.diameter(g_nx))\n",
    "        \n",
    "    print(\"total graphs: \", len(voc_dataset))\n",
    "    print(\"total nodes: \", total_nodes)\n",
    "    print(\"total edges: \", total_edges)\n",
    "    print(\"avg_nodes: \", total_nodes/len(voc_dataset)*1.0)\n",
    "    print(\"avg_edges: \", total_edges/len(voc_dataset)*1.0)\n",
    "    print(\"mean node deg: \", torch.mean(all_node_degs))\n",
    "    print(\"avg. of avg. shortest paths: \", np.mean(all_avg_shortest_paths))\n",
    "    print(\"std. of avg. shortest paths: \", np.std(all_avg_shortest_paths))\n",
    "    print(\"avg. diameter: \", np.mean(all_diameters))\n",
    "    print(\"std. diameter: \", np.std(all_diameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f8cea-b70d-4cf6-9de8-366410889d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_dataset = join_dataset_splits(\n",
    "        [VOCSuperpixels(root='../../datasets/VOCSuperpixels', name='edge_wt_only_coord',\n",
    "                        slic_compactness=10,\n",
    "                        split=split)\n",
    "         for split in ['train', 'val', 'test']]\n",
    "    )\n",
    "# get_stats(voc_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5a677-bbbe-4a73-abc9-228d7a1160fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_dataset = join_dataset_splits(\n",
    "        [VOCSuperpixels(root='../../datasets/VOCSuperpixels', name='edge_wt_region_boundary',\n",
    "                        slic_compactness=10,\n",
    "                        split=split)\n",
    "         for split in ['train', 'val', 'test']]\n",
    "    )\n",
    "get_stats(voc_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e932f6e3-2662-45b6-bd4d-7c71dc09d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_dataset = join_dataset_splits(\n",
    "        [COCOSuperpixels(root='../../datasets/COCOSuperpixels', name='edge_wt_only_coord',\n",
    "                        slic_compactness=10,\n",
    "                        split=split)\n",
    "         for split in ['train', 'val', 'test']]\n",
    "    )\n",
    "#get_stats(coco_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d76ff1-1199-43da-a85a-f7e246b617de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa9d3b7-cb6f-4ace-aeb6-b444d20acab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
